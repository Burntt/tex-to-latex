Original Figure:

\centering
\includegraphics[width=0.49\textwidth]{img/proposed_solution_trace_selection.pdf}
\caption{Trace sampling process for generalization training. Historical workload data are processed to extract container traces, which are clustered into representative groups.}
\label{fig:proposed_solution_trace_selection}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/proposed_solution_trace_selection.pdf}
\caption{Trace sampling process for generalization training. Historical workload data are processed to extract container traces, which are clustered into representative groups.}
\label{fig:proposed_solution_trace_selection}
\end{figure}


Original Figure:

\centering
\includegraphics[width=0.49\textwidth]{img/latent_space_creation.png}
\caption{Overview of the latent space extractor. The input $\mathcal{T}(t)$ is encoded into latent space $\mathcal{Z}(z)$ by $f_{\text{encoder}}$ and then decoded by $f_{\text{decoder}}$ to reconstruct $\mathcal{R}(t) \approx \mathcal{T}(t)$.}
\label{fig:latent_space_creation}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/latent_space_creation.png}
\caption{Overview of the latent space extractor. The input $\mathcal{T}
\label{fig:latent_space_creation}
\end{figure}


Original Figure:

\centering
\includegraphics[width=0.49\textwidth]{img/Transformer_Architecture.pdf}
\caption{High-level overview of the transformer architecture}
\label{fig:Transformer_Architecture}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/Transformer_Architecture.pdf}
\caption{High-level overview of the transformer architecture}
\label{fig:Transformer_Architecture}
\end{figure}


Original Figure:

\centering
\includegraphics[width=0.49\textwidth]{img/attention_goal.pdf}
\caption{Attention mechanism refining time-series embeddings $\mathbf{E}_i$ to $\mathbf{E}_i'$, with arrow thickness indicating the strength of influence.}
\label{fig:attention_goal}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/attention_goal.pdf}
\caption{Attention mechanism refining time-series embeddings $\mathbf{E}
\label{fig:attention_goal}
\end{figure}


Original Figure:

\centering
\includegraphics[width=0.42\textwidth]{img/attention_workings.pdf}
\caption{Multi-Headed Attention: Input embeddings ($\mathbf{E}_i$) are transformed into query ($\mathbf{Q}$), key ($\mathbf{K}$), and value ($\mathbf{V}$) vectors. Multiple heads ($H$) capture different temporal aspects. Larger circles indicate stronger attention scores.}
\label{fig:attention_workings}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/attention_workings.pdf}
\caption{Multi-Headed Attention: Input embeddings ($\mathbf{E}
\label{fig:attention_workings}
\end{figure}


Original Figure:

\centering
\includegraphics[width=0.42\textwidth]{img/gp_toy_example.pdf}
\caption{Bayesian optimization toy example. The star indicates the next value to try ($d_y = 5$). The target signifies the goal of minimizing the objective function.}
\label{fig:gp_toy_example}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/gp_toy_example.pdf}
\caption{Bayesian optimization toy example. The star indicates the next value to try ($d_y = 5$). The target signifies the goal of minimizing the objective function.}
\label{fig:gp_toy_example}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.49\textwidth]{img/test_rmse_distribution_histogram.pdf}
\caption{Sensitivity to Hyperparameters for Model Generalization}
\label{fig:test_rmse_distribution_histogram}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/test_rmse_distribution_histogram.pdf}
\caption{Sensitivity to Hyperparameters for Model Generalization}
\label{fig:test_rmse_distribution_histogram}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.49\textwidth]{img/metrics_comparison_regular.eps}
\caption{Generalization performance comparison of MAE, RMSE and SMAPE for each model for the \textbf{regular training} traces.}
\label{fig:metrics_comparison_regular}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/metrics_comparison_regular.eps}
\caption{Generalization performance comparison of MAE, RMSE and SMAPE for each model for the \textbf{regular training}
\label{fig:metrics_comparison_regular}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.42\textwidth]{img/metrics_comparison_zs.eps}
\caption{Generalization performance comparison of MAE, RMSE, and SMAPE for each model on the \textbf{zero-shot} traces.}
\label{fig:metrics_comparison_ZS}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/metrics_comparison_zs.eps}
\caption{Generalization performance comparison of MAE, RMSE, and SMAPE for each model on the \textbf{zero-shot}
\label{fig:metrics_comparison_ZS}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.42\textwidth]{img/pred_vs_inf.eps}
\caption{Impact of prediction length on inference time and RMSE for OmniFORE, AGCRN, and LSTNet.}
\label{fig:pred_vs_inf}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/pred_vs_inf.eps}
\caption{Impact of prediction length on inference time and RMSE for OmniFORE, AGCRN, and LSTNet.}
\label{fig:pred_vs_inf}
\end{figure}


Original Figure:

\centering
\includegraphics[width=0.42\textwidth]{img/dynamic_workload_changes.eps}
\caption{Comparison of true and predicted values for OmniFORE, AGCRN, and LSTNet under dynamic workload changes.}
\label{fig:dynamic_workload_changes}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/dynamic_workload_changes.eps}
\caption{Comparison of true and predicted values for OmniFORE, AGCRN, and LSTNet under dynamic workload changes.}
\label{fig:dynamic_workload_changes}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.42\textwidth]{img/zs_sample_trace_comparison.eps}
\caption{Comparison of true and \textbf{zero-shot} predicted values for OmniFORE, AGCRN, and LSTNet on a regular training dataset.}
\label{fig:zs_sample_trace_comparison}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/zs_sample_trace_comparison.eps}
\caption{Comparison of true and \textbf{zero-shot}
\label{fig:zs_sample_trace_comparison}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.47\textwidth]{img/metrics_variance_comparison_fitted2.eps}
\caption{Trace variance vs. MAE and RMSE for OmniFORE, AGCRN, and LSTNet models, with fitted linear lines.}
\label{fig:metrics_variance_comparison_fitted}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/metrics_variance_comparison_fitted2.eps}
\caption{Trace variance vs. MAE and RMSE for OmniFORE, AGCRN, and LSTNet models, with fitted linear lines.}
\label{fig:metrics_variance_comparison_fitted}
\end{figure}


Original Figure:
%[H]
\centering
\includegraphics[width=0.49\textwidth]{img/test_rmse_convergence_comparison.eps}
\caption{Convergence of OmniFORE, AGCRN, and LSTNet models over epochs.}
\label{fig:test_rmse_convergence_comparison}


Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/test_rmse_convergence_comparison.eps}
\caption{Convergence of OmniFORE, AGCRN, and LSTNet models over epochs.}
\label{fig:test_rmse_convergence_comparison}
\end{figure}


Original Figure:
[t]
% \centering
% \includegraphics[width=0.47\textwidth]{img/Practical_Scenario.pdf}
% \caption{Scalable ML deployment and inference for Edge-cloud orchestration.}
% \label{fig:Practical_Scenario}
% 

Formatted Figure:
\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{img/Practical_Scenario.pdf}
\caption{Scalable ML deployment and inference for Edge-cloud orchestration.}
\label{fig:Practical_Scenario}
\end{figure}


Total figures processed: 15
