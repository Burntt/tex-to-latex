@comment{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%}

@comment{%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%}

@comment{## Containers}

@comment{# rest}

@comment{##}

@article{gort2023forecasting,
  title={Forecasting Trends in Cloud/Edge Computing: Unleashing the Power of Attention Mechanisms},
  author={Gort, Berend and Kibalya, Godfrey and Serrano, Maria and Antonopoulos, Angelos},
  journal={IEEE Communications Magazine},
  note={To appear},
  doi={10.36227/techrxiv.24467740.v1},
  funder = {VERGE (SNS-JU-101096034), ETHER (SNS-JU-101096526), CLOUDSTARS (101086248), AEON-ZERO (TSI-063000-2021-52), FREE-6G (TSI-063000-2021-144), AROMA3D (TSI-063000-2021-70/71), 6G-OASIS (TSI-063000-2021-24), SUCCESS-6G (TSI-063000-2021-39/40/41), AVANZANDO-5G-GEMELOS DIGITALES (TSI-063000-2021-112/113/114)}
}


@ARTICLE{10417087,
  author={Abbasi, Mahmoud and Shahraki, Amin and Prieto, Javier and Arrieta, Angélica González and Corchado, Juan M.},
  journal={IEEE Transactions on Machine Learning in Communications and Networking}, 
  title={Unleashing the Potential of Knowledge Distillation for IoT Traffic Classification}, 
  year={2024},
  volume={2},
  number={},
  pages={221-239},
  keywords={Internet of Things;Computational modeling;Biological system modeling;Performance evaluation;Data models;Adaptation models;Neurons;Network traffic classification (NTC);IoT;machine learning;network management;knowledge distillation;IoT traffic classification},
  doi={10.1109/TMLCN.2024.3360915}}

@ARTICLE{10646623,
  author={Lyu, Xinchen and Li, Yuewei and He, Ying and Ren, Chenshan and Ni, Wei and Liu, Ren Ping and Zhu, Pengcheng and Cui, Qimei},
  journal={IEEE Transactions on Machine Learning in Communications and Networking}, 
  title={Objective-Driven Differentiable Optimization of Traffic Prediction and Resource Allocation for Split AI Inference Edge Networks}, 
  year={2024},
  volume={2},
  number={},
  pages={1178-1192},
  keywords={Resource management;Artificial intelligence;Optimization;Long short term memory;Predictive models;Computational modeling;Telecommunication traffic;Resource allocation;traffic prediction;differential optimization;split AI inference},
  doi={10.1109/TMLCN.2024.3449831}}

@article{zhang2019improving,
  title={Improving deep transformer with depth-scaled initialization and merged attention},
  author={Zhang, Biao and Titov, Ivan and Sennrich, Rico},
  journal={arXiv preprint arXiv:1908.11365},
  year={2019}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={2048--2057},
  year={2015},
  organization={PMLR}
}

@article{luong2015effective,
  title={Effective approaches to attention-based neural machine translation},
  author={Luong, Minh-Thang},
  journal={arXiv preprint arXiv:1508.04025},
  year={2015}
}

@article{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{lei2016layer,
  title={Layer normalization},
  author={Lei Ba, Jimmy and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={ArXiv e-prints},
  pages={arXiv--1607},
  year={2016}
}

@inproceedings{liu2023spatio,
  title={Spatio-temporal adaptive embedding makes vanilla transformer sota for traffic forecasting},
  author={Liu, Hangchen and Dong, Zheng and Jiang, Renhe and Deng, Jiewen and Deng, Jinliang and Chen, Quanjun and Song, Xuan},
  booktitle={Proceedings of the 32nd ACM international conference on information and knowledge management},
  pages={4125--4129},
  year={2023}
}

@article{kazemnejad2024impact,
  title={The impact of positional encoding on length generalization in transformers},
  author={Kazemnejad, Amirhossein and Padhi, Inkit and Natesan Ramamurthy, Karthikeyan and Das, Payel and Reddy, Siva},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{yue2022ts2vec,
  title={Ts2vec: Towards universal representation of time series},
  author={Yue, Zhihan and Wang, Yujing and Duan, Juanyong and Yang, Tianmeng and Huang, Congrui and Tong, Yunhai and Xu, Bixiong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={8980--8987},
  year={2022}
}

@article{10052731,
    author = {Zhang, Liangkang and Xie, Yulai and Jin, Minpeng and Zhou, Pan and Xu, Gongming and Wu, Yafeng and Feng, Dan and Long, Darrell},
    doi = {10.1109/TNSM.2023.3248803},
    journal = {IEEE Transactions on Network and Service Management},
    keywords = {Containers,Smoothing methods,Predictive models,Load modeling,Resource management,Logic gates,Time series analysis,Docker,workload prediction,LSTM,triple exponential smoothing},
    number = {3},
    pages = {2726-2743},
    title = {A Novel Hybrid Model for Docker Container Workload Prediction.},
    volume = {20},
    year = {2023}
}

@article{10068185,
    author = {Raeisi-Varzaneh, Mostafa and Dakkak, Omar and Habbal, Adib and Kim, Byung-Seo},
    doi = {10.1109/ACCESS.2023.3256522},
    journal = {IEEE ACCESS},
    keywords = {Task analysis,Processor scheduling,Edge computing,Cloud computing,Job shop scheduling,Resource management,Computational modeling,Edge computing,resource scheduling,task offloading,fairness,load balancing},
    number = {},
    pages = {25329-25350},
    title = {Resource Scheduling in Edge Computing: Architecture, Taxonomy, Open Issues and Future Research Directions.},
    volume = {11},
    year = {2023}
}

@article{10149092,
    author = {Ashraf, Qazi Mamoon and Tahir, Mohammad and Habaebi, Mohamed Hadi and Isoaho, Jouni},
    doi = {10.1109/JIOT.2023.3285359},
    journal = {IEEE Internet of Things Journal},
    keywords = {Internet of Things,Surveys,Security,Protocols,Computer architecture,Ecosystems,Cloud computing,Artificial intelligence (AI),autonomic computing,blockchain,edge computing,Internet of Things (IoT),machine learning (ML),self-* paradigm},
    number = {16},
    pages = {14725-14748},
    title = {Toward Autonomic Internet of Things: Recent Advances, Evaluation Criteria, and Future Research Directions.},
    volume = {10},
    year = {2023}
}

@inproceedings{10202641,
    author = {Qin, Xiaoting and others},
    booktitle = {2023 53rd Annual IEEE/IFLIP International Conference on Dependable Systems and Networks (dsn)},
    doi = {10.1109/DSN58367.2023.00055},
    keywords = {Cloud computing,Sensitivity,Knowledge based systems,Resource management,Reliability,Sustainable development,Optimization,Cloud workloads,workload characteristics,resource management},
    number = {},
    pages = {522-530},
    title = {How Different Are the Cloud Workloads? Characterizing Large-scale Private and Public Cloud Workloads.},
    volume = {},
    year = {2023}
}

@inproceedings{10228949,
    author = {Ouyang, Tao and Zhao, Kongyange and Zhang, Xiaoxi and Zhou, Zhi and Chen, Xu},
    booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
    doi = {10.1109/INFOCOM53939.2023.10228949},
    keywords = {Couplings,Machine learning algorithms,System dynamics,Heuristic algorithms,Machine learning,Quality of service,Prediction algorithms},
    number = {},
    pages = {1-10},
    title = {Dynamic Edge-centric Resource Provisioning for Online and Offline Services Co-location.},
    volume = {},
    year = {2023}
}

@inproceedings{10229034,
    author = {Shang, Xiaojun and Mao, Yingling and Liu, Yu and Huang, Yaodong and Liu, Zhenhua and Yang, Yuanyuan},
    booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
    doi = {10.1109/INFOCOM53939.2023.10229034},
    keywords = {Scheduling algorithms,Computational modeling,Serverless computing,Containers,Routing,Data models,Dispersion},
    number = {},
    pages = {1-10},
    title = {Online Container Scheduling for Data-intensive Applications in Serverless Edge Computing.},
    volume = {},
    year = {2023}
}

@inproceedings{10229064,
    author = {Collet, Alan and Bazco-Nogueras, Antonio and Banchs, Albert and Fiore, Marco},
    booktitle = {IEEE INFOCOM 2023 - IEEE Conference on Computer Communications},
    doi = {10.1109/INFOCOM53939.2023.10229064},
    keywords = {Metalearning,Codes,Computational modeling,Time series analysis,Predictive models,Data models,Quality of experience},
    number = {},
    pages = {1-10},
    title = {Automanager: a Meta-learning Model for Network Management from Intertwined Forecasts.},
    volume = {},
    year = {2023}
}

@INPROCEEDINGS{9500858,
  author={Nagib, Ahmad M. and others},
  booktitle={ICC 2021 - IEEE International Conference on Communications}, 
  title={Deep Learning-Based Forecasting of Cellular Network Utilization at Millisecond Resolutions}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  keywords={Cellular networks;Wireless networks;Memory architecture;Predictive models;Resource management;Forecasting;Task analysis;cellular network;resource utilization;time series forecasting;deep learning;LSTM;LTE},
  doi={10.1109/ICC42927.2021.9500858}}

@ARTICLE{8334540,
  title={Latency critical IoT applications in 5G: Perspective on the design of radio interface and network architecture},
  author={Schulz, Philipp and Matthe, Maximilian and Klessig, Henrik and Simsek, Meryem and Fettweis, Gerhard and Ansari, Junaid and Ashraf, Shehzad Ali and Almeroth, Bjoern and Voigt, Jens and Riedel, Ines and others},
  journal={IEEE Communications Magazine},
  volume={55},
  number={2},
  pages={70--78},
  year={2017},
  publisher={IEEE}
}

@article{10531701,
    author = {Gupta, Ishu and Saxena, Deepika and Singh, Ashutosh Kumar and Lee, Chung-Nan},
    doi = {10.1109/TPAMI.2024.3402061},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {Predictive models,Adaptation models,Qubit,Logic gates,Forecasting,Neural networks,Hidden Markov models,Quantum computing,machine learning,multiple-control Toffoli gates,qubits,uniform adaption,workload forecasting},
    number = {},
    pages = {1-16},
    title = {A Multiple Controlled Toffoli Driven Adaptive Quantum Neural Network Model for Dynamic Workload Prediction in Cloud Environments.},
    volume = {},
    year = {2024}
}

@inproceedings{8258257,
    author = {Lu, Chengzhi and others},
    booktitle = {2017 IEEE International Conference on Big Data (big Data)},
    doi = {10.1109/BigData.2017.8258257},
    keywords = {Cloud computing, Resource management, Runtime, Containers, Quality of service, Alibaba Trace, Imbalance, Container, Cloud Computing, Resource Efficiency},
    pages = {2884-2892},
    title = {Imbalance in the Cloud: an Analysis on Alibaba CLUSTER Trace.},
    year = {2017}
}

@inproceedings{9068614,
    author = {Guo, Jing and others},
    booktitle = {2019 IEEE/acm 27th International Symposium on Quality of Service (iwqos)},
    doi = {10.1145/3326285.3329074},
    keywords = {Resource management,Cloud computing,Production,Memory management,Containers,Servers,Resource efficiency,cloud computing,datacenter},
    number = {},
    pages = {1-10},
    title = {Who Limits the Resource Efficiency of My Datacenter: an Analysis of Alibaba Datacenter Traces.},
    volume = {},
    year = {2019}
}

@article{9889720,
    author = {Gonçalves, Tiago and Rio-Torto, Isabel and Teixeira, Luís F. and Cardoso, Jaime S.},
    doi = {10.1109/ACCESS.2022.3206449},
    journal = {IEEE ACCESS},
    keywords = {Biomedical imaging,Computer architecture,Transformers,Medical services,Deep learning,Artificial intelligence,Biomedical equipment,Computer vision,Artificial intelligence,attention mechanisms,computer vision,deep learning,medical applications,medical image analysis,transformers},
    number = {},
    pages = {98909-98935},
    title = {A Survey on Attention Mechanisms for Medical Applications: Are We Moving Toward Better Algorithms?.},
    volume = {10},
    year = {2022}
}

@inproceedings{acmtimeseriesreview2024,
    abstract = {Multivariate time series forecasting is a critical task with applications across various domains, including finance, energy demand, and climate modeling. This review paper, provides a comprehensive overview of methodologies and advancements in multivariate time series forecasting, focusing on deep learning architectures, ensemble methods, and modeling techniques. Traditional approaches such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs) have paved the way for modeling sequential data, but challenges remain in capturing long-term dependencies. Recent advancements in transformer-based architectures and graph neural networks (GNNs) have addressed these challenges, offering enhanced accuracy and interpretability. Ensemble methods, leveraging the strengths of multiple models, have emerged as effective strategies for improving forecast robustness. The review discusses key methodologies, including hybrid models, attention mechanisms, and deep learning architectures, highlighting their strengths and limitations. Through interdisciplinary collaboration and methodological innovation, researchers can address complex forecasting problems, ultimately benefiting society across a wide range of applications.},
    address = {New York, NY, USA},
    articleno = {58},
    author = {Mendis, Kasun and Wickramasinghe, Manjusri and Marasinghe, Pasindu},
    booktitle = {Proceedings of the 2024 2nd Asia Conference on Computer Vision, Image Processing and Pattern Recognition},
    doi = {10.1145/3663976.3664241},
    isbn = {9798400716607},
    keywords = {deep learning, machine learning, multivariate, time series forecasting},
    location = {Xiamen, China},
    numpages = {9},
    publisher = {Association for Computing Machinery},
    series = {CVIPPR '24},
    title = {Multivariate Time Series Forecasting: a Review.},
    url = {https://doi.org/10.1145/3663976.3664241},
    year = {2024}
}

@article{AGCRN,
    author = {Bai, Lei and Yao, Lina and Li, Can and Wang, Xianzhi and Wang, Can},
    journal = {Advances in Neural Information Processing Systems},
    pages = {17804-17815},
    title = {Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting.},
    volume = {33},
    year = {2020}
}

@article{al2023fhic,
    author = {Al-Alimi, Dalal and Cai, Zhihua and Al-qaness, Mohammed AA},
    journal = {IEEE Transactions on Geoscience and Remote Sensing},
    publisher = {IEEE},
    title = {FHIC: Fast Hyperspectral Image Classification Model Using ETR Dimensionality Reduction and ELU Activation Function.},
    year = {2023}
}

@article{benidis2022deep,
    author = {Benidis, Konstantinos and Rangapuram, Syama Sundar and Flunkert, Valentin and Wang, Yuyang and Maddix, Danielle and Turkmen, Caner and Gasthaus, Jan and Bohlke-Schneider, Michael and Salinas, David and Stella, Lorenzo and others},
    journal = {ACM Computing Surveys},
    number = {6},
    pages = {1-36},
    publisher = {ACM New York, NY},
    title = {Deep Learning for Time Series Forecasting: Tutorial and Literature Survey.},
    volume = {55},
    year = {2022}
}

@article{clusteringDL,
    author = {Zhao, Bendong and Lu, Huanzhang and Chen, Shangfeng and Liu, Junliang and Wu, Dongya},
    doi = {10.21629/JSEE.2017.01.18},
    journal = {Journal of Systems Engineering and Electronics},
    keywords = {Time series analysis,Convolution,Hidden Markov models,Training,Neural networks,Data mining,Neurons,time series,multivariate time series,classification,convolutional neural network (CNN),data mining},
    number = {1},
    pages = {162-169},
    title = {Convolutional Neural Networks for Time Series Classification.},
    volume = {28},
    year = {2017}
}

@article{fasterandlightertransformers,
    author = {Fournier, Quentin and others},
    journal = {ACM Computing Surveys},
    number = {14s},
    pages = {1-40},
    publisher = {ACM New York, NY},
    title = {A Practical Survey on Faster and Lighter Transformers.},
    volume = {55},
    year = {2023}
}

@article{fournier2023practical,
    author = {Fournier, Quentin and others},
    journal = {ACM Computing Surveys},
    number = {14s},
    pages = {1-40},
    publisher = {ACM New York, NY},
    title = {A Practical Survey on Faster and Lighter Transformers.},
    volume = {55},
    year = {2023}
}

@article{frazier2018tutorial,
    author = {Frazier, Peter I},
    journal = {Arxiv Preprint Arxiv:1807.02811},
    title = {A Tutorial on Bayesian Optimization.},
    year = {2018}
}

@misc{google2019cluster,
    author = {Google},
    howpublished = {\url{https://github.com/google/cluster-data/blob/master/ClusterData2019.md}},
    title = {CLUSTER Data Collected from Production Clusters in Google for CLUSTER Management Research.},
    year = {2019}
}

@inproceedings{gorbett2023sparse,
    author = {Gorbett, Matt and Shirazi, Hossein and Ray, Indrakshi},
    booktitle = {Proceedings of the 29th ACM Sigkdd Conference on Knowledge Discovery and Data Mining},
    pages = {544-556},
    title = {Sparse Binary Transformers for Multivariate Time Series Modeling.},
    year = {2023}
}

@inproceedings{gridsearchvsbayesian,
    author = {Alibrahim, Hussain and Ludwig, Simone A},
    booktitle = {2021 IEEE Congress on Evolutionary Computation (cec)},
    organization = {IEEE},
    pages = {1551-1559},
    title = {Hyperparameter Optimization: Comparing Genetic Algorithm against Grid Search and Bayesian Optimization.},
    year = {2021}
}

@article{gupta2020approaches,
    author = {Gupta, Ashish and Gupta, Hari Prabhat and Biswas, Bhaskar and Dutta, Tanima},
    journal = {IEEE Transactions on Artificial Intelligence},
    number = {1},
    pages = {47-61},
    publisher = {IEEE},
    title = {Approaches and Applications of Early Classification of Time Series: a Review.},
    volume = {1},
    year = {2020}
}

@article{he2023taxonomy,
    author = {He, Tianzhang and Buyya, Rajkumar},
    journal = {ACM Computing Surveys},
    number = {3},
    pages = {1-33},
    publisher = {ACM New York, NY},
    title = {A Taxonomy of Live Migration Management in Cloud Computing.},
    volume = {56},
    year = {2023}
}

@article{hochreiter1998vanishing,
    author = {Hochreiter, Sepp},
    journal = {International Journal of Uncertainty, Fuzziness and Knowledge-based Systems},
    number = {02},
    pages = {107-116},
    publisher = {World Scientific},
    title = {The Vanishing Gradient Problem during Learning Recurrent Neural Nets and Problem Solutions.},
    volume = {6},
    year = {1998}
}

@inproceedings{hyperparamsdatasets,
    abstract = {With the advent of automated machine learning, automated hyperparameter optimization methods are by now routinely used in data mining. However, this progress is not yet matched by equal progress on automatic analyses that yield information beyond performance-optimizing hyperparameter settings. In this work, we aim to answer the following two questions: Given an algorithm, what are generally its most important hyperparameters, and what are typically good values for these? We present methodology and a framework to answer these questions based on meta-learning across many datasets. We apply this methodology using the experimental meta-data available on OpenML to determine the most important hyperparameters of support vector machines, random forests and Adaboost, and to infer priors for all their hyperparameters. The results, obtained fully automatically, provide a quantitative basis to focus efforts in both manual algorithm design and in automated hyperparameter optimization. The conducted experiments confirm that the hyperparameters selected by the proposed method are indeed the most important ones and that the obtained priors also lead to statistically significant improvements in hyperparameter optimization.},
    address = {New York, NY, USA},
    author = {van Rijn, Jan N. and Hutter, Frank},
    booktitle = {Proceedings of the 24th ACM Sigkdd International Conference on Knowledge Discovery \& Data Mining},
    doi = {10.1145/3219819.3220058},
    isbn = {9781450355520},
    keywords = {meta-learning, hyperparameter optimization, hyperparameter importance},
    location = {London, United Kingdom},
    numpages = {10},
    pages = {2367–2376},
    publisher = {Association for Computing Machinery},
    series = {KDD '18},
    title = {Hyperparameter Importance Across Datasets.},
    url = {https://doi-org.recursos.biblioteca.upc.edu/10.1145/3219819.3220058},
    year = {2018}
}

@article{li2024evogwp,
    author = {Li, Jialun and Yao, Jieqian and Xiao, Danyang and Yang, Diying and Wu, Weigang},
    journal = {IEEE Transactions on Parallel and Distributed Systems},
    publisher = {IEEE},
    title = {Evogwp: Predicting Long-term Changes in Cloud Workloads Using Deep Graph-evolution Learning.},
    year = {2024}
}

@article{liang2023model,
    author = {Liang, Qianlin and Hanafy, Walid A and Ali-Eldin, Ahmed and Shenoy, Prashant},
    journal = {ACM Transactions on Autonomous and Adaptive Systems},
    number = {1},
    pages = {1-26},
    publisher = {ACM New York, NY},
    title = {Model-driven CLUSTER Resource Management for AI Workloads in Edge Clouds.},
    volume = {18},
    year = {2023}
}

@inproceedings{LSTNet,
    author = {Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
    booktitle = {The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
    pages = {95-104},
    title = {Modeling Long-and Short-term Temporal Patterns with Deep Neural Networks.},
    year = {2018}
}

@article{ma2024multivariate,
    author = {Ma, Shusen and Zhao, Yun-Bo and Kang, Yu and Bai, Peng},
    journal = {IEEE Transactions on Artificial Intelligence},
    publisher = {IEEE},
    title = {Multivariate Time Series Modeling and Forecasting with Parallelized Convolution and Decomposed Sparse-transformer.},
    year = {2024}
}

@article{nguyen2019host,
    author = {Nguyen, Hoang Minh and Kalra, Gaurav and Kim, Daeyoung},
    journal = {The Journal of Supercomputing},
    number = {11},
    pages = {7592-7605},
    publisher = {Springer},
    title = {Host Load Prediction in Cloud Computing Using Long Short-term Memory Encoder--decoder.},
    volume = {75},
    year = {2019}
}

@inproceedings{ouyang2023dynamic,
    author = {Ouyang, Tao and Zhao, Kongyange and Zhang, Xiaoxi and Zhou, Zhi and Chen, Xu},
    booktitle = {IEEE INFOCOM 2023-IEEE Conference on Computer Communications},
    organization = {IEEE},
    pages = {1-10},
    title = {Dynamic Edge-centric Resource Provisioning for Online and Offline Services Co-location.},
    year = {2023}
}

@inproceedings{pascanu2013difficulty,
    author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
    booktitle = {International Conference on Machine Learning},
    organization = {Pmlr},
    pages = {1310-1318},
    title = {On the Difficulty of Training Recurrent Neural Networks.},
    year = {2013}
}

@article{rejiba2019survey,
    author = {Rejiba, Zeineb and Masip-Bruin, Xavier and Marin-Tordera, Eva},
    journal = {ACM Computing Surveys (csur)},
    number = {5},
    pages = {1-33},
    publisher = {ACM New York, NY, USA},
    title = {A Survey on Mobility-induced Service Migration in the Fog, Edge, and Related Computing Paradigms.},
    volume = {52},
    year = {2019}
}

@article{RNNGAN,
    author = {Yazdanian, Peyman and Sharifian, Saeed},
    journal = {The Journal of Supercomputing},
    pages = {11052-11082},
    publisher = {Springer},
    title = {E2LG: a Multiscale Ensemble of Lstm/gan Deep Learning Architecture for Multistep-ahead Cloud Workload Prediction.},
    volume = {77},
    year = {2021}
}

@inproceedings{RPTCN,
    author = {Chen, Wenyan and Lu, Chengzhi and Ye, Kejiang and Wang, Yang and Xu, Cheng-Zhong},
    booktitle = {2021 IEEE International Conference on CLUSTER Computing (cluster)},
    doi = {10.1109/Cluster48925.2021.00038},
    keywords = {Deep learning,Cloud computing,Correlation,Uncertainty,Conferences,Computational modeling,Predictive models,cloud computing,resource prediction,high dynamic,deep learning},
    number = {},
    pages = {59-69},
    title = {RPTCN: Resource Prediction for High-dynamic Workloads in Clouds Based on Deep Learning.},
    volume = {},
    year = {2021}
}

@article{saxena2023performance,
    author = {Saxena, Deepika and Kumar, Jitendra and Singh, Ashutosh Kumar and Schmid, Stefan},
    journal = {IEEE Transactions on Parallel and Distributed Systems},
    number = {4},
    pages = {1313-1330},
    publisher = {IEEE},
    title = {Performance Analysis of Machine Learning Centered Workload Prediction Models for Cloud.},
    volume = {34},
    year = {2023}
}

@inproceedings{shang2023online,
    author = {Shang, Xiaojun and Mao, Yingling and Liu, Yu and Huang, Yaodong and Liu, Zhenhua and Yang, Yuanyuan},
    booktitle = {IEEE INFOCOM 2023-ieee Conference on Computer Communications},
    organization = {IEEE},
    pages = {1-10},
    title = {Online Container Scheduling for Data-intensive Applications in Serverless Edge Computing.},
    year = {2023}
}

@inproceedings{STRec,
    author = {Li, Chengxi and Wang, Yejing and Liu, Qidong and Zhao, Xiangyu and Wang, Wanyu and Wang, Yiqi and Zou, Lixin and Fan, Wenqi and Li, Qing},
    booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
    pages = {101-111},
    title = {STRec: Sparse Transformer for Sequential Recommendations.},
    year = {2023}
}

@inproceedings{strubell2020energy,
    author = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
    booktitle = {Proceedings of the Aaai Conference on Artificial Intelligence},
    number = {09},
    pages = {13693-13696},
    title = {Energy and Policy Considerations for Modern Deep Learning Research.},
    volume = {34},
    year = {2020}
}

@article{TimeLLM,
    author = {Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and others},
    journal = {Arxiv Preprint Arxiv:2310.01728},
    title = {Time-LLM: Time Series Forecasting by Reprogramming Large Language Models.},
    year = {2023}
}

@article{vaswani2017attention,
    author = {Vaswani, Ashish and others},
    journal = {Advances in Neural Information Processing Systems},
    title = {Attention is All You Need.},
    volume = {30},
    year = {2017}
}

@article{wen2022transformers,
    author = {Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
    journal = {Arxiv Preprint Arxiv:2202.07125},
    title = {Transformers in Time Series: a Survey.},
    year = {2022}
}

@article{xu2022esdnn,
    author = {Xu, Minxian and others},
    journal = {ACM Transactions on Internet Technology (toit)},
    number = {3},
    pages = {1-24},
    publisher = {ACM New York, NY},
    title = {ESDNN: Deep Neural Network Based Multivariate Workload Prediction in Cloud Computing Environments.},
    volume = {22},
    year = {2022}
}

@inproceedings{ye2018modeling,
    author = {Ye, Kejiang and Kou, Yanmin and Lu, Chengzhi and Wang, Yang and Xu, Cheng-Zhong},
    booktitle = {2018 IEEE 24th International Conference on Parallel and Distributed Systems (icpads)},
    organization = {IEEE},
    pages = {1-6},
    title = {Modeling Application Performance in Docker Containers Using Machine Learning Techniques.},
    year = {2018}
}

@article{yuan2024improved,
    author = {Yuan, Haitao and Bi, Jing and Li, Shuang and Zhang, Jia and Zhou, MengChu},
    journal = {IEEE Internet of Things Journal},
    publisher = {IEEE},
    title = {An Improved LSTM-based Prediction Approach for Resources and Workload in Large-scale Data Centers.},
    year = {2024}
}

@article{zhang2023novel,
    author = {Zhang, Liangkang and others},
    journal = {IEEE Transactions on Network and Service Management},
    number = {3},
    pages = {2726-2743},
    publisher = {IEEE},
    title = {A Novel Hybrid Model for Docker Container Workload Prediction.},
    volume = {20},
    year = {2023}
}

@inproceedings{zhou2021informer,
    author = {Zhou, Haoyi and others},
    booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
    number = {12},
    pages = {11106-11115},
    title = {Informer: Beyond Efficient Transformer for Long Sequence Time-series Forecasting.},
    volume = {35},
    year = {2021}
}

@article{zhu2023online,
    author = {Zhu, Konglin and Chen, Wentao and Jiao, Lei and Wang, Jiaxing and Peng, Yuyang and Zhang, Lin},
    journal = {Computer Networks},
    pages = {109556},
    publisher = {Elsevier},
    title = {Online Training Data Acquisition for Federated Learning in Cloud--edge Networks.},
    volume = {223},
    year = {2023}
}
