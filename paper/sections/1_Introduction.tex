\section{INTRODUCTION}
\label{Section: Introduction}

\IEEEPARstart{D}{espite} significant strides in cloud computing~\cite{10229034}, optimizing resource utilization in edge-cloud networks remains challenging due to the ever-changing nature of cloud-native workloads~\cite{10646623}. Recently, workload prediction has emerged as crucial for service orchestration and resource management in edge-cloud networks \cite{10068185}. Accurate workload prediction facilitates the proactive and efficient allocation of computational resources based on real-time requirements, minimizing both over-provisioning and under-provisioning~\cite{10229064, 8258257, 9068614}. However, achieving precise workload predictions is complex due to factors such as shifts in user demand and workload migrations~\cite{ouyang2023dynamic}, leading to discrepancies between training models and real-world conditions. These temporally inconsistent events occurring at various timescales degrade prediction accuracy and orchestration efficiency~\cite{saxena2023performance}. This issue is particularly challenging for container-level workloads due to poor resource isolation across containers, short container lifespans, high container density, and low data generation per container~\cite{10417087, 10202641}. The growing prevalence of microservice applications, where different microservices are independently deployed across containers requiring separate elasticity operations, further underscores the importance of accurate container-level workload prediction~\cite{10202641, shang2023online, 10052731}.

Given the dynamic nature of cloud-native workloads, efforts have focused on developing machine learning models capable of generalizing well to unseen data. Recurrent Neural Networks (RNNs) have been explored for predicting workloads but face challenges like declining memory and limitations in sequential processing \cite{hochreiter1998vanishing, benidis2022deep}. Convolutional Neural Networks (CNNs) were used to capture local patterns in time-series data, but struggled with long-term dependencies \cite{acmtimeseriesreview2024}. Hybrid models combining CNN and RNN architectures have been developed to address these issues \cite{xu2022esdnn}. Integration of Graph Neural Networks (GNNs) and Generative Adversarial Networks (GANs) into RNNs has shown promise in capturing both spatial and temporal information \cite{li2024evogwp, RNNGAN, AGCRN}. Despite these advancements, these hybrid models still face limitations inherent to their RNN and CNN components.


Recent advancements in machine learning for time-series forecasting have introduced the attention mechanism \cite{vaswani2017attention}, which enhances workload prediction models by selectively focusing on crucial segments of the input sequence to assess the importance of different data points \cite{gort2023forecasting}. This capability to identify complex patterns and dependencies greatly benefits generalization \cite{9889720}. Nonetheless, traditional attention mechanisms can be computationally heavy, posing challenges for resource-limited edge-cloud environments. To overcome these issues, recent studies have shifted towards more efficient and lightweight transformers \cite{fasterandlightertransformers}, utilizing sparse attention techniques \cite{gorbett2023sparse, STRec, ma2024multivariate} that minimize the number of connections within the model. For example, the informer model \cite{zhou2021informer} employs sparse attention to achieve efficiency and scalability when handling extensive time-series datasets, effectively capturing intricate dependencies and long-range correlations. Informers significantly enhance computational efficiency and speed, making them a viable alternative to traditional transformer models and enabling precise resource management and improved service quality in edge-cloud computing environments.

In this paper, we introduce \textbf{OmniFORE} (\textbf{F}ramework for \textbf{O}ptimization of \textbf{R}esource forecasts in \textbf{E}dge-cloud networks). In particular, we combine attention-based time-series models with temporal clustering to achieve robust generalization and efficiently consume and predict diverse workloads in volatile environments. Our approach addresses the limitations of traditional RNN and CNN models by utilizing informers, which implement sparse attention to effectively handle long-term dependencies and complex patterns in extensive time-series data. Temporal clustering of time-series enables strategic training on representative subsets from large datasets, capturing both short-term stability and long-term dynamic changes in container-level features. This ensures robust performance even with previously unseen data. Furthermore, our method includes an efficient data sampling strategy that reduces computational overhead, ensuring reliable performance across diverse workload scenarios. Extensive experiments with real-world data confirm the superiority of our approach, demonstrating higher prediction accuracy and significantly faster inference speeds compared to state-of-the-art (SoA) methods. Our primary contribution is threefold:

\begin{enumerate}
\item We introduce \textbf{attention-based models with temporal clustering of time-series} to ensure model generalization in edge-cloud networks.
\item We develop \textbf{a data sampling strategy} that minimizes computational overhead while maintaining high performance.
\item We evaluate OmniFORE with real-world data, demonstrating \textbf{superior prediction accuracy and faster inference speeds}.
\end{enumerate}

The remainder of this paper is organized as follows: Section~\ref{sec: related works} provides a comprehensive review of related literature. Section~\ref{sec: System Model} delineates our system model and elucidates the generalization challenges inherent in edge-cloud networks. In Section~\ref{sec: Proposed Solution}, we present our novel approach, with particular emphasis on our attention mechanisms and clustering techniques. Section~\ref{sec: Performance Evaluation} offers a rigorous analysis of our experimental results. Finally, we conclude the paper by synthesizing our key findings.

