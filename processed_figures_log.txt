Processed Figure 1:

\centering
\includegraphics[width=0.8\textwidth]{img/proposed_solution_trace_selection.pdf}
\caption{Trace sampling process for generalization training. Historical workload data are processed to extract container traces, which are clustered into representative groups.}
\label{fig:proposed_solution_trace_selection}


Processed Figure 2:

\centering
\includegraphics[width=0.8\textwidth]{img/latent_space_creation.png}
\caption{Overview of the latent space extractor. The input $\mathcal{T}
\label{fig:latent_space_creation}


Processed Figure 3:

\centering
\includegraphics[width=0.8\textwidth]{img/Transformer_Architecture.pdf}
\caption{High-level overview of the transformer architecture}
\label{fig:Transformer_Architecture}


Processed Figure 4:

\centering
\includegraphics[width=0.8\textwidth]{img/attention_goal.pdf}
\caption{Attention mechanism refining time-series embeddings $\mathbf{E}
\label{fig:attention_goal}


Processed Figure 5:

\centering
\includegraphics[width=0.8\textwidth]{img/attention_workings.pdf}
\caption{Multi-Headed Attention: Input embeddings ($\mathbf{E}
\label{fig:attention_workings}


Processed Figure 6:

\centering
\includegraphics[width=0.8\textwidth]{img/gp_toy_example.pdf}
\caption{Bayesian optimization toy example. The star indicates the next value to try ($d_y = 5$). The target signifies the goal of minimizing the objective function.}
\label{fig:gp_toy_example}


Processed Figure 7:

\centering
\includegraphics[width=0.8\textwidth]{img/test_rmse_distribution_histogram.pdf}
\caption{Sensitivity to Hyperparameters for Model Generalization}
\label{fig:test_rmse_distribution_histogram}


Processed Figure 8:

\centering
\includegraphics[width=0.8\textwidth]{img/metrics_comparison_regular.eps}
\caption{Generalization performance comparison of MAE, RMSE and SMAPE for each model for the \textbf{regular training}
\label{fig:metrics_comparison_regular}


Processed Figure 9:

\centering
\includegraphics[width=0.8\textwidth]{img/metrics_comparison_zs.eps}
\caption{Generalization performance comparison of MAE, RMSE, and SMAPE for each model on the \textbf{zero-shot}
\label{fig:metrics_comparison_ZS}


Processed Figure 10:

\centering
\includegraphics[width=0.8\textwidth]{img/pred_vs_inf.eps}
\caption{Impact of prediction length on inference time and RMSE for OmniFORE, AGCRN, and LSTNet.}
\label{fig:pred_vs_inf}


Processed Figure 11:

\centering
\includegraphics[width=0.8\textwidth]{img/dynamic_workload_changes.eps}
\caption{Comparison of true and predicted values for OmniFORE, AGCRN, and LSTNet under dynamic workload changes.}
\label{fig:dynamic_workload_changes}


Processed Figure 12:

\centering
\includegraphics[width=0.8\textwidth]{img/zs_sample_trace_comparison.eps}
\caption{Comparison of true and \textbf{zero-shot}
\label{fig:zs_sample_trace_comparison}


Processed Figure 13:

\centering
\includegraphics[width=0.8\textwidth]{img/metrics_variance_comparison_fitted2.eps}
\caption{Trace variance vs. MAE and RMSE for OmniFORE, AGCRN, and LSTNet models, with fitted linear lines.}
\label{fig:metrics_variance_comparison_fitted}


Processed Figure 14:

\centering
\includegraphics[width=0.8\textwidth]{img/test_rmse_convergence_comparison.eps}
\caption{Convergence of OmniFORE, AGCRN, and LSTNet models over epochs.}
\label{fig:test_rmse_convergence_comparison}


Processed Figure 15:

\centering
\includegraphics[width=0.8\textwidth]{img/Practical_Scenario.pdf}
\caption{Scalable ML deployment and inference for Edge-cloud orchestration.}
\label{fig:Practical_Scenario}


